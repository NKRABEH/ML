{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/n_k_rabeh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import keras.utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions needed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face1(filename, required_size=(224, 224)):\n",
    "    # load image from file\n",
    "    if type(filename)==str:\n",
    "        pixels = cv2.imread(filename) # le parmètre entré est le path d'un fichier image    \n",
    "    else:\n",
    "        pixels=filename.astype('uint8') # le parmètre entré estun fichier image\n",
    "    if np.shape(pixels)==(224,224,3):\n",
    "        face_array=pixels[:,:,::-1]\n",
    "        return face_array\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    if results == []:\n",
    "        return(results)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    face_array=face_array[:,:,::-1]\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the different variables needed for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training and validation directory locations\n",
    "train_dir=\"./Dataset/train/\"\n",
    "val_dir=\"./Dataset/validation/\"\n",
    "#image used for training and validation have fixed dimensions\n",
    "img_width, image_height = 224, 224\n",
    "\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if your train you model on jupyter, make sure to delete hidden files in Dataset/train and validation. ( e.g. '.ipynb_checkpoints').\\\n",
    "command is : rm -r .ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the class labels based on train directory\n",
    "labels = os.listdir(train_dir)\n",
    "labels=[labels[i].split('/')[-1] for i in range(len(labels))]\n",
    "\n",
    "np.save(open('labels.npy', 'wb'),labels)\n",
    "total_classes = len(labels)\n",
    "\n",
    "#Number of training and validation images.\n",
    "nTrain = sum([len(files) for r,d, files in os.walk(train_dir)])\n",
    "nValidation = sum([len(files) for r,d, files in os.walk(val_dir)])\n",
    "\n",
    "#check the labels of the different classes\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1288 images belonging to 7 classes.\n",
      "Found 244 images belonging to 7 classes.\n",
      "WARNING:tensorflow:From /home/n_k_rabeh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/n_k_rabeh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/n_k_rabeh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/15\n",
      "644/644 [==============================] - 440s 684ms/step - loss: 2.1527 - acc: 0.4092 - val_loss: 1.6246 - val_acc: 0.4754\n",
      "Epoch 2/15\n",
      "644/644 [==============================] - 433s 672ms/step - loss: 1.0158 - acc: 0.6483 - val_loss: 1.7956 - val_acc: 0.7254\n",
      "Epoch 3/15\n",
      "644/644 [==============================] - 631s 979ms/step - loss: 0.6894 - acc: 0.7787 - val_loss: 0.0320 - val_acc: 0.5328\n",
      "Epoch 4/15\n",
      "644/644 [==============================] - 490s 761ms/step - loss: 0.5038 - acc: 0.8300 - val_loss: 1.3878 - val_acc: 0.7172\n",
      "Epoch 5/15\n",
      "644/644 [==============================] - 429s 666ms/step - loss: 0.3803 - acc: 0.8680 - val_loss: 1.5976 - val_acc: 0.7295\n",
      "Epoch 6/15\n",
      "644/644 [==============================] - 427s 664ms/step - loss: 0.2447 - acc: 0.9255 - val_loss: 1.0758 - val_acc: 0.7869\n",
      "Epoch 7/15\n",
      "644/644 [==============================] - 426s 662ms/step - loss: 0.1895 - acc: 0.9363 - val_loss: 0.0159 - val_acc: 0.8156\n",
      "Epoch 8/15\n",
      "644/644 [==============================] - 429s 666ms/step - loss: 0.1419 - acc: 0.9511 - val_loss: 0.0036 - val_acc: 0.8607\n",
      "Epoch 9/15\n",
      "644/644 [==============================] - 426s 662ms/step - loss: 0.1294 - acc: 0.9565 - val_loss: 1.7880 - val_acc: 0.8484\n",
      "Epoch 10/15\n",
      "644/644 [==============================] - 426s 662ms/step - loss: 0.1174 - acc: 0.9651 - val_loss: 1.6364 - val_acc: 0.8033\n",
      "Epoch 11/15\n",
      "644/644 [==============================] - 429s 666ms/step - loss: 0.0863 - acc: 0.9697 - val_loss: 0.0392 - val_acc: 0.7992\n",
      "Epoch 12/15\n",
      "644/644 [==============================] - 427s 664ms/step - loss: 0.0584 - acc: 0.9837 - val_loss: 0.8599 - val_acc: 0.8566\n",
      "Epoch 13/15\n",
      "644/644 [==============================] - 428s 665ms/step - loss: 0.0313 - acc: 0.9938 - val_loss: 13.2152 - val_acc: 0.8689\n",
      "Epoch 14/15\n",
      "644/644 [==============================] - 429s 666ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9221\n",
      "Epoch 15/15\n",
      "644/644 [==============================] - 426s 661ms/step - loss: 0.0297 - acc: 0.9907 - val_loss: 0.1496 - val_acc: 0.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f39da66b828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model \n",
    "\n",
    "#Generate data (training and validation)\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_width, image_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True)\n",
    "\n",
    "generator_val = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size = (img_width, image_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode =\"categorical\",\n",
    "    shuffle = True)\n",
    "\n",
    "\n",
    "#build base model \n",
    "vgg_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3),  pooling=None )\n",
    "\n",
    "# add missing layers\n",
    "last_layer = vgg_model.output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(total_classes, activation=None, name='classifier')(x)\n",
    "out = Activation('softmax')(x)\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=vgg_model.input, outputs=out)\n",
    "\n",
    "# We retrain all layers except the first layer\n",
    "# i.e. freeze only first layer\n",
    "model.layers[0].trainable = False\n",
    "sgd = optimizers.SGD(lr = 0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "# compile the model \n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics= [ \"acc\"])\n",
    "\n",
    "#Train\n",
    "model.fit_generator(generator, epochs=15,validation_data=generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Personnes=[]\n",
    "for X in os.listdir('./Dataset/train/'):\n",
    "    for y in os.listdir('./Dataset/train/'+X):\n",
    "        filename = './Dataset/train/'+X+'/'+y\n",
    "        Personnes.append(filename)\n",
    "        break\n",
    "personnes=[personne.split('/')[3] for personne in Personnes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ordered classes\n",
    "classe=[0]*total_classes\n",
    "for X in Personnes:\n",
    "    img = image.load_img(X, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    predictions=model.predict(x)\n",
    "    print(X,predictions[0])\n",
    "  \n",
    "    classe[np.argmax(predictions[0])]=X.split('/')[3]\n",
    "print(\"les classe sont : \", classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
